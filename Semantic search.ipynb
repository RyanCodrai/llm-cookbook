{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0532c768",
   "metadata": {},
   "source": [
    "# Semantic search\n",
    "\n",
    "There are several use-cases where we might want to search amongst a large corpus of text. Examples include:\n",
    "- Powering a search engine\n",
    "- Detecting near duplicate texts\n",
    "- Finding similar texts to reccomend to users\n",
    "- Retrieving factual information to provide context to large language models\n",
    "\n",
    "By using embeddings we can encode our search query as a series of related concepts rather than lexical symbols. This is what it means to capture the semantics of the search query. Let's look at how we can build out python code to enable semantic search. We'll use OpenAI's embeddings along with the Annoy (approximate nearest neighbours) library published by Spotify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62450fb",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "For our dataset we'll use texts about the marvel cinematic universe taken from wikipedia. Let's load the article texts and also store the article names (which are the filenames) for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e8a0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "def read_text_file(filename: str) -> str:\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "    \n",
    "def extract_filename(path: str) -> str:\n",
    "    return os.path.basename(path)\n",
    "\n",
    "\n",
    "paths = glob('datasets/marvel/*.txt')\n",
    "texts = {extract_filename(path): read_text_file(path) for path in paths}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3e729",
   "metadata": {},
   "source": [
    "# Loading OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f031b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from the environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f9da5",
   "metadata": {},
   "source": [
    "# Retrieving OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "267784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import concurrent\n",
    "import numpy as np\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    return openai.Embedding.create(input=[text], model=model)['data'][0]['embedding']\n",
    "\n",
    "\n",
    "def parallel_embedding(text_list, model=\"text-embedding-ada-002\"):\n",
    "    # Create a ThreadPoolExecutor\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "        # Submit tasks to the executor and remember the order\n",
    "        futures = []\n",
    "        mapping = dict()\n",
    "        for i, text in enumerate(text_list):\n",
    "            future = executor.submit(get_embedding, text, model)\n",
    "            futures.append(future)\n",
    "            mapping[future] = i\n",
    "\n",
    "        # Retrieve results as they become available and sort their order\n",
    "        embeddings = [None] * len(futures)\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            embeddings[mapping[future]] = future.result()\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1f9f1",
   "metadata": {},
   "source": [
    "# Embedding our dataset\n",
    "Although we could look at methods of embedding each article to create one dense vector per article we need to consider that embedding models have a token limit but also the loss of granularity as local information or specific details might be averaged out or overshadowed by the dominant themes of the article.\n",
    "\n",
    "To capture the full meaning and context within our articles, it's essential to treat the text with care when dividing it into chunks for embedding. A naive approach might inadvertently slice a sentence in half, causing a loss of vital context. Imagine having a sentence where the first part poses a question and the second part delivers an answer. If these two segments were separated, the overall understanding of that information would be compromised.\n",
    "\n",
    "For our embedding process, we employ a strategy that aims to preserve context. We divide each article into segments containing 256 tokens. To achieve this, we implement a sliding window mechanism. The window spans 256 tokens of the text, and for each step, it moves by 192 tokens. This means that consecutive chunks will overlap by 64 tokens, ensuring that they share roughly one-third of their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c491a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2953 text chunks from 46 texts.\n",
      "Retrieved embeddings in 9.93s\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_with_sliding_window(text: str, window_size: int = 256, stride: int = 192, model_name: str = \"text-embedding-ada-002\") -> list:\n",
    "    enc = tiktoken.encoding_for_model(model_name)\n",
    "    tokens = enc.encode(text)\n",
    "\n",
    "    chunks = []\n",
    "    current_position = 0\n",
    "\n",
    "    while current_position + window_size <= len(tokens):\n",
    "        chunk_tokens = tokens[current_position:current_position + window_size]\n",
    "        chunks.append(enc.decode(chunk_tokens))\n",
    "        current_position += stride\n",
    "\n",
    "    # Handle the tail if any tokens remain\n",
    "    if current_position < len(tokens):\n",
    "        chunks.append(enc.decode(tokens[-window_size:]))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "text_chunks = list()\n",
    "for filename, text in texts.items():\n",
    "    template = 'Article title: \"\"\"{filename}\"\"\"\\nText: \"\"\"{text}\"\"\"'\n",
    "    for chunk in split_with_sliding_window(text):\n",
    "        text_chunks.append(template.format(filename=filename, text=chunk))\n",
    "        \n",
    "text_chunks = np.array(text_chunks)\n",
    "\n",
    "start_time = time.time()\n",
    "embeddings = parallel_embedding(text_chunks)\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print(f'Created {len(text_chunks)} text chunks from {len(texts)} texts.')\n",
    "print(f'Retrieved embeddings in {round(duration, 2)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1cac53",
   "metadata": {},
   "source": [
    "# Creating the search index\n",
    "We use the annoy python library to build an efficient approximate nearest neighbours search index that we can use to search for embeddings similar to the embedding of our search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f898e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "search_index = AnnoyIndex(embeddings.shape[1], 'angular')\n",
    "# Add all the vectors to the search index\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    search_index.add_item(i, embedding)\n",
    "\n",
    "search_index.build(10) # 10 trees\n",
    "search_index.save('index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a73df893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search(query):\n",
    "    # Get the query's embedding\n",
    "    query_embedding = parallel_embedding([query])[0]\n",
    "\n",
    "#   # Retrieve the nearest neighbors\n",
    "    similar_item_ids = search_index.get_nns_by_vector(\n",
    "        query_embedding,\n",
    "        3,\n",
    "        include_distances=True\n",
    "    )\n",
    "\n",
    "    # Format the results\n",
    "    results = pd.DataFrame(\n",
    "        data={\n",
    "            'texts': text_chunks[similar_item_ids[0]],\n",
    "            'distance': similar_item_ids[1]\n",
    "        }\n",
    "    )    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f373204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: \"\"\"Avengers- Infinity War.txt\"\"\"\n",
      "Text: \"\"\"ige added that Thanos believes the universe is becoming over-populated, which led to the destruction of his home moon Titan and is something he vowed not to let happen again,[56] and also said \"you could almost go so far as to say he is the main character of\" the film.[58] McFeely shared this sentiment, describing the film as his \"hero journey\" in addition to being the film's protagonist, stating, \"Part of that is the things that [mean] the most to him. We wanted to show that. It wasn't just power; it wasn't just an ideal; it was people\".[26] Brolin likened Thanos to \"the Quasimodo of this time\" and the novel Perfume, since Thanos was born deformed and considered a \"freak\" on Titan,[59] while Joe Russo would reference The Godfather (1972) for Brolin at times, which Brolin felt helped \"to emotionalize the whole thing\".[60] Brolin further added that he preferred playing Thanos over Cable in Deadpool 2 (2018) because of the amount of work that went into creating the character.[61] Thanos does not wear armor for most of the\"\"\"\n",
      "\n",
      "Article title: \"\"\"Avengers- Infinity War.txt\"\"\"\n",
      "Text: \"\"\"cée and the CEO of Stark Industries.[53] Downey felt that \"Pepper remains the heart of the [Iron Man] story\", which was not a focal point in some of the preceding films with Stark. Downey continued that \"we wanted to get back to that reality. Not just for them, but let's really see how that can add to the something-worth-fighting-for of it all\".[9]\n",
      "Benicio del Toro as Taneleer Tivan / The Collector: One of the Elders of the Universe who is an obsessive keeper of the largest collection of interstellar fauna, relics, and species of all manner in the galaxy.[54]\n",
      "Josh Brolin as Thanos:\n",
      "An intergalactic warlord from Titan who seeks all six Infinity Stones to destroy half of all life[55][24][56] for the sake of \"re-balanc[ing] the universe\".[57] Producer Kevin Feige added that Thanos believes the universe is becoming over-populated, which led to the destruction of his home moon Titan and is something he vowed not to let happen again,[56] and also said \"you could almost go so far as to say he is the main character of\" the film.[58] McFe\"\"\"\n",
      "\n",
      "Article title: \"\"\"The Avengers (2012 film).txt\"\"\"\n",
      "Text: \"\"\" action movie. Things tend to hurtle toward the screen anyway\".[118] In January 2012, it was reported that the film would be digitally remastered for IMAX 3D and would open in IMAX theaters on May 4, 2012, the same day it opened in regular theaters. The IMAX release followed Marvel's IMAX releases of Iron Man 2 and Thor.[119]\n",
      "\n",
      "In a May 2012 interview, Whedon said that it was his decision to include Thanos in a post-credits scene, although the character is not identified in the film. \"He for me is the most powerful and fascinating Marvel villain. He's the great grand daddy of the badasses and he's in love with Death and I just think that's so cute. For me, the greatest Avengers [comic book] was Avengers Annual #7 (1977) that Jim Starlin did followed by Marvel Two-in-One Annual #2 (1977) that contained the death of Adam Warlock. Those were some of the most important texts and I think underrated milestones in Marvel history and Thanos is all over that, so somebody had to be in control and had to be behind Loki's work and I was like 'It's got to be\"\"\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Thanos?\"\n",
    "print(search(query).texts[0])\n",
    "print()\n",
    "print(search(query).texts[1])\n",
    "print()\n",
    "print(search(query).texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a38424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
