{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf33fcd",
   "metadata": {},
   "source": [
    "# Near duplicate detection\n",
    "\n",
    "Near-duplicate detection in texts refers to the process of identifying documents or text segments that are almost, but not exactly, the same. These near-duplicates might differ in terms of a few words, punctuation, formatting, or minor rephrasing, but they convey very similar or identical information.\n",
    "\n",
    "Applications of near duplicate detection include:\n",
    "- Search Engines: To improve diversity of search results by filtering out duplicate pages that have substantially the same content.\n",
    "- Plagiarism Detection: To identify instances where a text might have been copied with minor modifications.\n",
    "- Data Deduplication: In large data repositories, it's important to avoid storing multiple near-identical versions of the same document. This is especially important in machine learning as duplicate texts may lead to imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61417f",
   "metadata": {},
   "source": [
    "# Loading OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5414c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the .env file in the parent directory\n",
    "env_path = Path(\"..\") / \".env\"\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Get the OpenAI API key from the environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e193ec5",
   "metadata": {},
   "source": [
    "#Â The dataset\n",
    "\n",
    "The dataset we'll be using comes from Kaggle and can be found [here](https://www.kaggle.com/datasets/stackoverflow/statsquestions). This dataset contains questions and answers from the cross-validated stack exchange (which is the machine learning equivilant of stack overflow). We'll use near-duplicate detection to find duplicate questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac71d7",
   "metadata": {},
   "source": [
    "# High-level approach\n",
    "To achieve near duplicate detection using text embeddings we'll:\n",
    "- Split our texts into segments\n",
    "- Retrieve embeddings for each of our segments\n",
    "- Find the n most similar segments for each segment\n",
    "- Record which segment pairs are have similarity higher than some threshold\n",
    "- Provide an easy way of removing texts from a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0928c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
